{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "831773bd-cfca-4e3c-8841-926c160e04c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row ID           0\n",
      "Order ID         0\n",
      "Order Date       0\n",
      "Ship Date        0\n",
      "Ship Mode        0\n",
      "Customer ID      0\n",
      "Customer Name    0\n",
      "Segment          0\n",
      "Country          0\n",
      "City             0\n",
      "State            0\n",
      "Postal Code      0\n",
      "Region           0\n",
      "Product ID       0\n",
      "Category         0\n",
      "Sub-Category     0\n",
      "Product Name     0\n",
      "Sales            0\n",
      "Quantity         0\n",
      "Discount         0\n",
      "Profit           0\n",
      "dtype: int64\n",
      "    Row ID        Order ID  Order Date   Ship Date       Ship Mode  \\\n",
      "0        1  CA-2016-152156   11/8/2016  11/11/2016    Second Class   \n",
      "2        3  CA-2016-138688   6/12/2016   6/16/2016    Second Class   \n",
      "3        4  US-2015-108966  10/11/2015  10/18/2015  Standard Class   \n",
      "5        6  CA-2014-115812    6/9/2014   6/14/2014  Standard Class   \n",
      "12      13  CA-2017-114412   4/15/2017   4/20/2017  Standard Class   \n",
      "13      14  CA-2016-161389   12/5/2016  12/10/2016  Standard Class   \n",
      "14      15  US-2015-118983  11/22/2015  11/26/2015  Standard Class   \n",
      "16      17  CA-2014-105893  11/11/2014  11/18/2014  Standard Class   \n",
      "17      18  CA-2014-167164   5/13/2014   5/15/2014    Second Class   \n",
      "18      19  CA-2014-143336   8/27/2014    9/1/2014    Second Class   \n",
      "\n",
      "   Customer ID       Customer Name      Segment        Country  \\\n",
      "0     CG-12520         Claire Gute     Consumer  United States   \n",
      "2     DV-13045     Darrin Van Huff    Corporate  United States   \n",
      "3     SO-20335      Sean O'Donnell     Consumer  United States   \n",
      "5     BH-11710     Brosina Hoffman     Consumer  United States   \n",
      "12    AA-10480        Andrew Allen     Consumer  United States   \n",
      "13    IM-15070        Irene Maddox     Consumer  United States   \n",
      "14    HP-14815       Harold Pawlan  Home Office  United States   \n",
      "16    PK-19075           Pete Kriz     Consumer  United States   \n",
      "17    AG-10270     Alejandro Grove     Consumer  United States   \n",
      "18    ZD-21925  Zuschuss Donatelli     Consumer  United States   \n",
      "\n",
      "               City  ... Postal Code   Region       Product ID  \\\n",
      "0         Henderson  ...       42420    South  FUR-BO-10001798   \n",
      "2       Los Angeles  ...       90036     West  OFF-LA-10000240   \n",
      "3   Fort Lauderdale  ...       33311    South  FUR-TA-10000577   \n",
      "5       Los Angeles  ...       90032     West  FUR-FU-10001487   \n",
      "12          Concord  ...       28027    South  OFF-PA-10002365   \n",
      "13          Seattle  ...       98103     West  OFF-BI-10003656   \n",
      "14       Fort Worth  ...       76106  Central  OFF-AP-10002311   \n",
      "16          Madison  ...       53711  Central  OFF-ST-10004186   \n",
      "17      West Jordan  ...       84084     West  OFF-ST-10000107   \n",
      "18    San Francisco  ...       94109     West  OFF-AR-10003056   \n",
      "\n",
      "           Category Sub-Category  \\\n",
      "0         Furniture    Bookcases   \n",
      "2   Office Supplies       Labels   \n",
      "3         Furniture       Tables   \n",
      "5         Furniture  Furnishings   \n",
      "12  Office Supplies        Paper   \n",
      "13  Office Supplies      Binders   \n",
      "14  Office Supplies   Appliances   \n",
      "16  Office Supplies      Storage   \n",
      "17  Office Supplies      Storage   \n",
      "18  Office Supplies          Art   \n",
      "\n",
      "                                         Product Name     Sales  Quantity  \\\n",
      "0                   Bush Somerset Collection Bookcase  261.9600         2   \n",
      "2   Self-Adhesive Address Labels for Typewriters b...   14.6200         2   \n",
      "3       Bretford CR4500 Series Slim Rectangular Table  957.5775         5   \n",
      "5   Eldon Expressions Wood and Plastic Desk Access...   48.8600         7   \n",
      "12                                         Xerox 1967   15.5520         3   \n",
      "13        Fellowes PB200 Plastic Comb Binding Machine  407.9760         3   \n",
      "14  Holmes Replacement Filter for HEPA Air Cleaner...   68.8100         5   \n",
      "16  Stur-D-Stor Shelving, Vertical 5-Shelf: 72\"H x...  665.8800         6   \n",
      "17                         Fellowes Super Stor/Drawer   55.5000         2   \n",
      "18                                         Newell 341    8.5600         2   \n",
      "\n",
      "    Discount    Profit  \n",
      "0       0.00   41.9136  \n",
      "2       0.00    6.8714  \n",
      "3       0.45 -383.0310  \n",
      "5       0.00   14.1694  \n",
      "12      0.20    5.4432  \n",
      "13      0.20  132.5922  \n",
      "14      0.80 -123.8580  \n",
      "16      0.00   13.3176  \n",
      "17      0.00    9.9900  \n",
      "18      0.00    2.4824  \n",
      "\n",
      "[10 rows x 21 columns]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'D:\\Power Bi Uss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProfit\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProfit\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m#save file with new name \u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mPower Bi Uss\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mcleanddataproject.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mD:\\New folder\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\New folder\\Lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[0;32m   3968\u001b[0m     path_or_buf,\n\u001b[0;32m   3969\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   3970\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[0;32m   3971\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   3972\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   3973\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   3974\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[0;32m   3975\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   3976\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m   3977\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   3978\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   3979\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[0;32m   3980\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[0;32m   3981\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[0;32m   3982\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[0;32m   3983\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   3984\u001b[0m )\n",
      "File \u001b[1;32mD:\\New folder\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mD:\\New folder\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    254\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    255\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,\n\u001b[0;32m    256\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression,\n\u001b[0;32m    257\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options,\n\u001b[0;32m    258\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mD:\\New folder\\Lib\\site-packages\\pandas\\io\\common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[1;32m--> 749\u001b[0m     check_parent_directory(\u001b[38;5;28mstr\u001b[39m(handle))\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32mD:\\New folder\\Lib\\site-packages\\pandas\\io\\common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'D:\\Power Bi Uss'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (correcting the file path)\n",
    "df = pd.read_csv(r\"C:\\Power Bi Uss\\sales project.csv\", encoding='latin-1')\n",
    "\n",
    "# Display first 10 rows\n",
    "#print(df.head(10))\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Fill missing values in 'sales' and 'Quantity' columns with 0\n",
    "df['Sales'] = df['Sales'].fillna(0)\n",
    "df['Quantity'] = df['Quantity'].fillna(0)\n",
    "\n",
    "# Drop rows where 'Order ID' is NULL\n",
    "df = df.dropna(subset=['Order ID'])\n",
    "\n",
    "# Remove duplicates based on 'Order ID'\n",
    "df = df.drop_duplicates(subset=['Order ID'])\n",
    "\n",
    "# Display cleaned data\n",
    "print(df.head(10))\n",
    "\n",
    "#change datatype to data \n",
    "df['Order Date'] = pd.to_datetime(df['Order Date'])\n",
    "df['Ship Date'] = pd.to_datetime(df['Ship Date'])\n",
    "\n",
    "#ensure numeric fields have numeric data only\n",
    "#errors ='coerce' will convert alphabets to NaN (Not a number)\n",
    "df['Sales'] = pd.to_numeric(df['Sales'], errors='coerce')\n",
    "df['Quantity'] = pd.to_numeric(df['Quantity'], errors='coerce')\n",
    "df['Discount'] = pd.to_numeric(df['Discount'], errors='coerce')\n",
    "df['Profit'] = pd.to_numeric(df['Profit'], errors='coerce')\n",
    "\n",
    "#save file with new name \n",
    "df.to_csv(\"D:\\\\Power Bi Uss\\\\cleanddataproject.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ca46fb-13f2-49d6-b3f3-bd9e1bd2bce1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
